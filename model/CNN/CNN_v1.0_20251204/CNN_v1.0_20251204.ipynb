{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === check gpu ===\n",
    "!nvidia-smi -L || true\n",
    "!pip -q install torch torchvision timm gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40906,
     "status": "ok",
     "timestamp": 1764857145117,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "FEHX8hMIkT8H",
    "outputId": "db351058-c67e-4fb2-c9fa-b980ffb7272f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-defcd148-6cbc-abdc-1a1b-39ecdb32b80b)\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# ==== basic libraries ====\n",
    "import os, zipfile, shutil, json, math, random, time, textwrap\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ==== Deep Learning ====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, models\n",
    "import timm\n",
    "\n",
    "# ==== Data Science ====\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== mount google drive ====\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1764859249328,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "HSv7angFryqo",
    "outputId": "83124822-8159-45ee-f510-4bac9d2a11b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==== file path setting ====\n",
    "\n",
    "# type A: file path in drive (/content/drive/MyDrive/...)\n",
    "ZIP_PATH_IN_DRIVE = \"/content/drive/MyDrive/2025_project_dataset_cls/2025_project_data_CNN_1204.zip\"  # ←有就填，沒有就留空字串\n",
    "# type B: file url (support drive share link or general http(s) direct link)\n",
    "ZIP_FILE_URL = \"\"       # if you have a file url, fill it in\n",
    "\n",
    "\n",
    "# save results to drive (can be modified)\n",
    "SAVE_TO_DRIVE_DIR = \"/content/drive/MyDrive/Colab_Results/leaf_stage1_cls\"\n",
    "\n",
    "\n",
    "# training parameters (can be modified)\n",
    "CFG = dict (\n",
    "    seed=42,\n",
    "    img_size=224,\n",
    "    batch_size=64,           # colab T4/RAM 通常可用 64；OOM 就降 32/16\n",
    "    num_workers=2,\n",
    "    epochs=25,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    model_name=\"mobilenetv3_large_100\",  # timm 名稱（或用 torchvision 官方 MobileNetV3-Large）\n",
    "    mixup_p=0.0,            # 分類任務可選擇關閉\n",
    "    label_smoothing=0.05,\n",
    "    early_stop_patience=7\n",
    ")\n",
    "\n",
    "# ==== random seed setting ====\n",
    "random.seed(CFG[\"seed\"]); np.random.seed(CFG[\"seed\"]); torch.manual_seed(CFG[\"seed\"])\n",
    "\n",
    "# ==== device setting ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92710,
     "status": "ok",
     "timestamp": 1764859349845,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "sa8-qajps-Ln",
    "outputId": "7f7ebe41-6ca0-4bcf-9393-10877d52366e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 由 Drive 複製 zip -> /content/dataset_zip/data.zip\n",
      "[OK] 解壓完成： /content/dataset_zip/unzipped\n"
     ]
    }
   ],
   "source": [
    "# ==== download zip file and unzip ====\n",
    "DATA_ROOT = Path(\"/content/dataset_zip\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "zip_local = DATA_ROOT / \"data.zip\"\n",
    "\n",
    "if ZIP_PATH_IN_DRIVE:\n",
    "    # copy from drive\n",
    "    src = Path(ZIP_PATH_IN_DRIVE)\n",
    "    assert src.exists(), f\"找不到：{src}\"\n",
    "    shutil.copy(str(src), str(zip_local))\n",
    "    print(f\"[OK] 由 Drive 複製 zip -> {zip_local}\")\n",
    "elif ZIP_FILE_URL:\n",
    "    import gdown, re\n",
    "    url = ZIP_FILE_URL.strip()\n",
    "    # support various google drive share links\n",
    "    m = re.search(r\"/d/([-\\w]{20,})\", url)\n",
    "    if m:\n",
    "        file_id = m.group(1)\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    gdown.download(url, str(zip_local), quiet=False)\n",
    "    print(f\"[OK] 透過連結下載 zip -> {zip_local}\")\n",
    "else:\n",
    "    raise ValueError(\"請設定 ZIP_PATH_IN_DRIVE 或 ZIP_FILE_URL 其中之一。\")\n",
    "\n",
    "assert zip_local.exists(), \"zip 檔案不存在\"\n",
    "\n",
    "UNZIP_DIR = DATA_ROOT / \"unzipped\"\n",
    "if UNZIP_DIR.exists():\n",
    "    shutil.rmtree(UNZIP_DIR)\n",
    "UNZIP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_local, 'r') as zf:\n",
    "    zf.extractall(UNZIP_DIR)\n",
    "print(\"[OK] 解壓完成：\", UNZIP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1764859354176,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "0fp9-m3NtbYo",
    "outputId": "43e0c63c-5723-4f77-8d71-9479a636f4a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dir: /content/dataset_zip/unzipped/2025_project_data_CNN_1204/train\n",
      "val_dir  : /content/dataset_zip/unzipped/2025_project_data_CNN_1204/val\n",
      "\n",
      "[train 類別資料夾]\n",
      "['whole_plant', 'potato', 'tomato', 'pepper_bell', 'others']\n",
      "[val 類別資料夾]\n",
      "['whole_plant', 'potato', 'tomato', 'pepper_bell', 'others']\n"
     ]
    }
   ],
   "source": [
    "# ==== find train/ val/ folder ====\n",
    "def find_train_val(root: Path):\n",
    "    # some zip files have an outer shell folder; here try to find train/ val/\n",
    "    candidates = [root] + [p for p in root.iterdir() if p.is_dir()]\n",
    "    for base in candidates:\n",
    "        t = base / \"train\"\n",
    "        v = base / \"val\"\n",
    "        if t.exists() and v.exists():\n",
    "            return t, v\n",
    "    raise RuntimeError(\"在解壓路徑中找不到 train/ 與 val/ 目錄\")\n",
    "\n",
    "train_dir, val_dir = find_train_val(UNZIP_DIR)\n",
    "print(\"train_dir:\", train_dir)\n",
    "print(\"val_dir  :\", val_dir)\n",
    "\n",
    "# check class folders\n",
    "print(\"\\n[train class folders]\")\n",
    "print([p.name for p in train_dir.iterdir() if p.is_dir()])\n",
    "print(\"[val class folders]\")\n",
    "print([p.name for p in val_dir.iterdir() if p.is_dir()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1764859359383,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "snn1xswJu6ye",
    "outputId": "ea966132-c5de-4112-b5d9-12732a869e87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['others', 'pepper_bell', 'potato', 'tomato', 'whole_plant'], 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforms and Dataset/DataLoader\n",
    "IMG_SIZE = CFG[\"img_size\"]\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(str(train_dir), transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(str(val_dir),   transform=val_tfms)\n",
    "class_names = train_ds.classes\n",
    "num_classes = len(class_names)\n",
    "class_names, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1764859361617,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "iArASaICvAYN",
    "outputId": "bb1e962a-ce14-41aa-a554-2f57c527099e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train 各類別張數]： {'others': 1492, 'pepper_bell': 1980, 'potato': 1721, 'tomato': 2000, 'whole_plant': 1594}\n"
     ]
    }
   ],
   "source": [
    "# ==== class imbalance handling (WeightedRandomSampler) ====\n",
    "from collections import Counter\n",
    "\n",
    "train_targets = [y for _, y in train_ds.imgs]\n",
    "cnt = Counter(train_targets)\n",
    "print(\"[train 各類別張數]：\", {class_names[k]: v for k,v in cnt.items()})\n",
    "\n",
    "# according to 1/frequency as weight, to alleviate imbalance\n",
    "sample_weights = np.array([1.0 / cnt[y] for y in train_targets], dtype=np.float32)\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=CFG[\"batch_size\"], sampler=sampler,\n",
    "    num_workers=CFG[\"num_workers\"], pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=CFG[\"batch_size\"], shuffle=False,\n",
    "    num_workers=CFG[\"num_workers\"], pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1764859364185,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "zI-w7t5BvFcA",
    "outputId": "7fcdab4c-e170-427e-9e67-b667b7d6fec2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1159147919.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
     ]
    }
   ],
   "source": [
    "# create model \n",
    "# use timm version (faster, pretrained weights are complete)\n",
    "model = timm.create_model(CFG[\"model_name\"], pretrained=True, num_classes=num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\n",
    "optimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2523998,
     "status": "ok",
     "timestamp": 1764861891073,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "UXXlid6svW2V",
    "outputId": "aabcd6c3-bd77-4457-f190-f32b850bc382"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3456122206.py:36: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
      "/tmp/ipython-input-3456122206.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/25 | train_loss 0.5850 | val_loss 0.4997 | val_acc 0.9437\n",
      "Epoch 02/25 | train_loss 0.3122 | val_loss 0.3724 | val_acc 0.9617\n",
      "Epoch 03/25 | train_loss 0.2776 | val_loss 0.3518 | val_acc 0.9686\n",
      "Epoch 04/25 | train_loss 0.2586 | val_loss 0.3347 | val_acc 0.9686\n",
      "Epoch 05/25 | train_loss 0.2502 | val_loss 0.3088 | val_acc 0.9772\n",
      "Epoch 06/25 | train_loss 0.2452 | val_loss 0.3223 | val_acc 0.9723\n",
      "Epoch 07/25 | train_loss 0.2412 | val_loss 0.3112 | val_acc 0.9715\n",
      "Epoch 08/25 | train_loss 0.2375 | val_loss 0.3022 | val_acc 0.9739\n",
      "Epoch 09/25 | train_loss 0.2352 | val_loss 0.3051 | val_acc 0.9739\n",
      "Epoch 10/25 | train_loss 0.2338 | val_loss 0.3006 | val_acc 0.9739\n",
      "Epoch 11/25 | train_loss 0.2315 | val_loss 0.2912 | val_acc 0.9755\n",
      "Epoch 12/25 | train_loss 0.2317 | val_loss 0.2925 | val_acc 0.9764\n",
      "[Early Stop] patience=7\n",
      "Best acc: 0.9771708112515287  | best path: /content/runs/cls/20251204_144247/best_mobilenetv3_large.pth\n"
     ]
    }
   ],
   "source": [
    "# training/validation loop (with early stopping)\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    loss_sum, n = 0.0, 0\n",
    "    all_probs, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "            probs = logits.softmax(1).detach().cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(y.detach().cpu().numpy())\n",
    "    avg_loss = loss_sum / n\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    preds = all_probs.argmax(1)\n",
    "    acc = (preds == all_targets).mean()\n",
    "    return avg_loss, acc, all_probs, all_targets\n",
    "\n",
    "def train_epochs(model, train_loader, val_loader, epochs, save_dir):\n",
    "    best_acc, best_path = -1, None\n",
    "    history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "    patience = CFG[\"early_stop_patience\"]\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss_sum, n = 0.0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss_sum += loss.item() * x.size(0)\n",
    "            n += x.size(0)\n",
    "\n",
    "        train_loss = train_loss_sum / n\n",
    "        val_loss, val_acc, _, _ = evaluate(model, val_loader)\n",
    "\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(float(val_acc))\n",
    "        print(f\"Epoch {epoch:02d}/{epochs} | train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_acc {val_acc:.4f}\")\n",
    "\n",
    "        # save best weights + early stopping\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            wait = 0\n",
    "            best_path = save_dir / \"best_mobilenetv3_large.pth\"\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(f\"[Early Stop] patience={patience}\")\n",
    "                break\n",
    "\n",
    "    # save training curves\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1); plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"train_loss\"); plt.plot(history[\"epoch\"], history[\"val_loss\"], label=\"val_loss\"); plt.legend(); plt.title(\"Loss\")\n",
    "    plt.subplot(1,2,2); plt.plot(history[\"epoch\"], history[\"val_acc\"], label=\"val_acc\"); plt.legend(); plt.title(\"Val Acc\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir / \"results_curves.png\", dpi=160); plt.close()\n",
    "\n",
    "    with open(save_dir / \"history.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "\n",
    "    return best_path, best_acc\n",
    "\n",
    "# create output folder\n",
    "RUN_DIR = Path(\"/content/runs/cls\") / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "best_path, best_acc = train_epochs(model, train_loader, val_loader, CFG[\"epochs\"], RUN_DIR)\n",
    "print(\"Best acc:\", best_acc, \" | best path:\", best_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28231,
     "status": "ok",
     "timestamp": 1764864842960,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "a4mrFx_sGZkd",
    "outputId": "57cbc978-f9ee-4cc5-bd1a-480ef5d06200"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3456122206.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VALID] loss=0.3088 acc=0.9772\n",
      "\n",
      "[Classification Report]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      others     1.0000    0.8940    0.9440       500\n",
      " pepper_bell     0.9357    1.0000    0.9668       495\n",
      "      potato     0.9795    0.9977    0.9885       431\n",
      "      tomato     0.9842    0.9960    0.9901       500\n",
      " whole_plant     0.9906    1.0000    0.9953       527\n",
      "\n",
      "    accuracy                         0.9772      2453\n",
      "   macro avg     0.9780    0.9775    0.9769      2453\n",
      "weighted avg     0.9782    0.9772    0.9768      2453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== use best weights for complete evaluation (confusion matrix / PR curves / report) ====\n",
    "# reload best weights\n",
    "model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "val_loss, val_acc, probs, targets = evaluate(model, val_loader)\n",
    "preds = probs.argmax(1)\n",
    "\n",
    "print(f\"[VALID] loss={val_loss:.4f} acc={val_acc:.4f}\")\n",
    "print(\"\\n[Classification Report]\\n\", classification_report(targets, preds, target_names=class_names, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(targets, preds, labels=list(range(num_classes)))\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(ax=ax, cmap=\"Blues\", colorbar=False, xticks_rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR / \"confusion_matrix.png\", dpi=200); plt.close()\n",
    "\n",
    "# PR Curves (each class)\n",
    "plt.figure(figsize=(6,5))\n",
    "for i, name in enumerate(class_names):\n",
    "    y_true = (targets == i).astype(int)\n",
    "    precision, recall, _ = precision_recall_curve(y_true, probs[:, i])\n",
    "    ap = average_precision_score(y_true, probs[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{name} AP={ap:.3f}\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curves\"); plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR / \"pr_curves.png\", dpi=200); plt.close()\n",
    "\n",
    "# save report text\n",
    "with open(RUN_DIR / \"classification_report.txt\", \"w\") as f:\n",
    "    f.write(classification_report(targets, preds, target_names=class_names, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31950,
     "status": "ok",
     "timestamp": 1764864918231,
     "user": {
      "displayName": "Nina Yih",
      "userId": "01177122349699776638"
     },
     "user_tz": -480
    },
    "id": "5huqLUSFJG8Q",
    "outputId": "c8e6794f-3827-4b4b-bf08-1d63bae2f3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 已將結果複製到：/content/drive/MyDrive/Colab_Results/leaf_stage1_cls/20251204_144247\n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "# ==== save results to drive ====\n",
    "SAVE_DIR = Path(SAVE_TO_DRIVE_DIR) / RUN_DIR.name\n",
    "SAVE_DIR.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# copy results\n",
    "if SAVE_DIR.exists():\n",
    "    shutil.rmtree(SAVE_DIR)\n",
    "shutil.copytree(RUN_DIR, SAVE_DIR)\n",
    "\n",
    "print(f\"[OK] 已將結果複製到：{SAVE_DIR}\")\n",
    "\n",
    "# extra: also copy the zip file and \"detected train/val structure\" for reference\n",
    "shutil.copy(str(zip_local), str(SAVE_DIR / \"source_dataset.zip\"))\n",
    "with open(SAVE_DIR / \"dataset_paths.txt\", \"w\") as f:\n",
    "    f.write(f\"train_dir: {train_dir}\\nval_dir  : {val_dir}\\nclasses  : {class_names}\\n\")\n",
    "print(\"[DONE]\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNRXyDjCxad7fljmVz/kocR",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "leaf_disease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
