{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPyvvbNxas3mreJpqWbb+8y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEHX8hMIkT8H","executionInfo":{"status":"ok","timestamp":1765252003574,"user_tz":-480,"elapsed":7374,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}},"outputId":"7fdf4842-16cf-481c-ca3f-7b2a0382398f"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU 0: Tesla T4 (UUID: GPU-0eda0d5e-eca6-0004-e2b9-1ed9ce0c0f08)\n","Mounted at /content/drive\n"]}],"source":["# ==== 0) 基本環境 ====\n","!nvidia-smi -L || true\n","!pip -q install torch torchvision timm gdown\n","\n","import os, zipfile, shutil, json, math, random, time, textwrap\n","from pathlib import Path\n","from datetime import datetime\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from torchvision import datasets, transforms, models\n","import timm\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_curve, average_precision_score\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"]},{"cell_type":"code","source":["# ==== 1) ①資料來源設定（\"二選一\" 取用你方便的方式）====\n","\n","# 方式 A：你已把 zip 放在「我的雲端硬碟」；填寫路徑（例：/content/drive/MyDrive/leaf_cls.zip）\n","ZIP_PATH_IN_DRIVE = \"/content/drive/MyDrive/2025_project_dataset_cls/2025_project_data_CNN_1204.zip\"  # ←有就填，沒有就留空字串\n","\n","# 方式 B：只有分享網址；把網址貼到這裡（支援 drive 分享連結或一般 http(s) 直連）\n","ZIP_FILE_URL = \"\"       # ←有就貼，沒有就留空字串\n","\n","# (可改) 最終成果要存回雲端的資料夾\n","SAVE_TO_DRIVE_DIR = \"/content/drive/MyDrive/Colab_Results/leaf_stage1_cls\"\n","\n","# (可改) 訓練常用參數\n","CFG = dict(\n","    seed=42,\n","    img_size=224,\n","    batch_size=64,           # Colab T4/RAM 通常可用 64；OOM 就降 32/16\n","    num_workers=2,\n","    epochs=25,\n","    lr=3e-4,\n","    weight_decay=1e-4,\n","    model_name=\"mobilenetv3_large_100\",  # timm 名稱（或用 torchvision 官方 MobileNetV3-Large）\n","    mixup_p=0.0,            # 分類任務可選擇關閉\n","    label_smoothing=0.05,\n","    early_stop_patience=7\n",")\n","\n","random.seed(CFG[\"seed\"]); np.random.seed(CFG[\"seed\"]); torch.manual_seed(CFG[\"seed\"])\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSv7angFryqo","executionInfo":{"status":"ok","timestamp":1765252006262,"user_tz":-480,"elapsed":21,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}},"outputId":"b25da315-715a-4a9a-92d0-70a66a551a4c"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# ==== 2) 下載/複製 zip 到 /content，並解壓 ====\n","DATA_ROOT = Path(\"/content/dataset_zip\")\n","DATA_ROOT.mkdir(parents=True, exist_ok=True)\n","\n","zip_local = DATA_ROOT / \"data.zip\"\n","\n","if ZIP_PATH_IN_DRIVE:\n","    # 從 MyDrive 複製\n","    src = Path(ZIP_PATH_IN_DRIVE)\n","    assert src.exists(), f\"找不到：{src}\"\n","    shutil.copy(str(src), str(zip_local))\n","    print(f\"[OK] 由 Drive 複製 zip -> {zip_local}\")\n","elif ZIP_FILE_URL:\n","    import gdown, re\n","    url = ZIP_FILE_URL.strip()\n","    # 支援各種 google drive 分享連結\n","    m = re.search(r\"/d/([-\\w]{20,})\", url)\n","    if m:\n","        file_id = m.group(1)\n","        url = f\"https://drive.google.com/uc?id={file_id}\"\n","    gdown.download(url, str(zip_local), quiet=False)\n","    print(f\"[OK] 透過連結下載 zip -> {zip_local}\")\n","else:\n","    raise ValueError(\"請設定 ZIP_PATH_IN_DRIVE 或 ZIP_FILE_URL 其中之一。\")\n","\n","assert zip_local.exists(), \"zip 檔案不存在\"\n","\n","UNZIP_DIR = DATA_ROOT / \"unzipped\"\n","if UNZIP_DIR.exists():\n","    shutil.rmtree(UNZIP_DIR)\n","UNZIP_DIR.mkdir(parents=True, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_local, 'r') as zf:\n","    zf.extractall(UNZIP_DIR)\n","print(\"[OK] 解壓完成：\", UNZIP_DIR)\n"],"metadata":{"id":"sa8-qajps-Ln","executionInfo":{"status":"aborted","timestamp":1765249454630,"user_tz":-480,"elapsed":6819,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== 3) 自動偵測 train/ 與 val/ 的實際所在資料夾 ====\n","def find_train_val(root: Path):\n","    # 有些壓縮會多一層外殼資料夾；這裡嘗試往下找到 train/ val/\n","    candidates = [root] + [p for p in root.iterdir() if p.is_dir()]\n","    for base in candidates:\n","        t = base / \"train\"\n","        v = base / \"val\"\n","        if t.exists() and v.exists():\n","            return t, v\n","    raise RuntimeError(\"在解壓路徑中找不到 train/ 與 val/ 目錄\")\n","\n","train_dir, val_dir = find_train_val(UNZIP_DIR)\n","print(\"train_dir:\", train_dir)\n","print(\"val_dir  :\", val_dir)\n","\n","# 檢查類別資料夾\n","print(\"\\n[train 類別資料夾]\")\n","print([p.name for p in train_dir.iterdir() if p.is_dir()])\n","print(\"[val 類別資料夾]\")\n","print([p.name for p in val_dir.iterdir() if p.is_dir()])\n"],"metadata":{"id":"0fp9-m3NtbYo","executionInfo":{"status":"aborted","timestamp":1765249454646,"user_tz":-480,"elapsed":6833,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== 4) Transforms 與 Dataset/DataLoader ====\n","IMG_SIZE = CFG[\"img_size\"]\n","\n","train_tfms = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.RandomHorizontalFlip(p=0.5),\n","    transforms.RandomRotation(10),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n","])\n","\n","val_tfms = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n","])\n","\n","train_ds = datasets.ImageFolder(str(train_dir), transform=train_tfms)\n","val_ds   = datasets.ImageFolder(str(val_dir),   transform=val_tfms)\n","class_names = train_ds.classes\n","num_classes = len(class_names)\n","class_names, num_classes\n"],"metadata":{"id":"snn1xswJu6ye","executionInfo":{"status":"aborted","timestamp":1765249454647,"user_tz":-480,"elapsed":6832,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== 5) 類別不平衡處理（WeightedRandomSampler） ====\n","from collections import Counter\n","\n","train_targets = [y for _, y in train_ds.imgs]\n","cnt = Counter(train_targets)\n","print(\"[train 各類別張數]：\", {class_names[k]: v for k,v in cnt.items()})\n","\n","# 依照 1/frequency 當作權重，緩解不平衡\n","sample_weights = np.array([1.0 / cnt[y] for y in train_targets], dtype=np.float32)\n","sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n","\n","train_loader = DataLoader(\n","    train_ds, batch_size=CFG[\"batch_size\"], sampler=sampler,\n","    num_workers=CFG[\"num_workers\"], pin_memory=True\n",")\n","val_loader = DataLoader(\n","    val_ds, batch_size=CFG[\"batch_size\"], shuffle=False,\n","    num_workers=CFG[\"num_workers\"], pin_memory=True\n",")\n"],"metadata":{"id":"iArASaICvAYN","executionInfo":{"status":"aborted","timestamp":1765249454669,"user_tz":-480,"elapsed":1,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== 6) 建立 MobileNetV3-Large 模型 ====\n","# 選用 timm 版本（速度快、預訓練權重齊全）\n","model = timm.create_model(CFG[\"model_name\"], pretrained=True, num_classes=num_classes)\n","model.to(device)\n","\n","# 損失與優化器\n","criterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\n","optimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\n","scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"],"metadata":{"id":"zI-w7t5BvFcA","executionInfo":{"status":"aborted","timestamp":1765249454671,"user_tz":-480,"elapsed":6853,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== 7) 訓練/驗證 迴圈（含早停） ====\n","def evaluate(model, loader):\n","    model.eval()\n","    loss_sum, n = 0.0, 0\n","    all_probs, all_targets = [], []\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n","                logits = model(x)\n","                loss = criterion(logits, y)\n","            loss_sum += loss.item() * x.size(0)\n","            n += x.size(0)\n","            probs = logits.softmax(1).detach().cpu().numpy()\n","            all_probs.append(probs)\n","            all_targets.append(y.detach().cpu().numpy())\n","    avg_loss = loss_sum / n\n","    all_probs = np.concatenate(all_probs)\n","    all_targets = np.concatenate(all_targets)\n","    preds = all_probs.argmax(1)\n","    acc = (preds == all_targets).mean()\n","    return avg_loss, acc, all_probs, all_targets\n","\n","def train_epochs(model, train_loader, val_loader, epochs, save_dir):\n","    best_acc, best_path = -1, None\n","    history = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n","    patience = CFG[\"early_stop_patience\"]\n","    wait = 0\n","\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss_sum, n = 0.0, 0\n","        for x, y in train_loader:\n","            x, y = x.to(device), y.to(device)\n","            optimizer.zero_grad(set_to_none=True)\n","            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n","                logits = model(x)\n","                loss = criterion(logits, y)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            train_loss_sum += loss.item() * x.size(0)\n","            n += x.size(0)\n","\n","        train_loss = train_loss_sum / n\n","        val_loss, val_acc, _, _ = evaluate(model, val_loader)\n","\n","        history[\"epoch\"].append(epoch)\n","        history[\"train_loss\"].append(train_loss)\n","        history[\"val_loss\"].append(val_loss)\n","        history[\"val_acc\"].append(float(val_acc))\n","        print(f\"Epoch {epoch:02d}/{epochs} | train_loss {train_loss:.4f} | val_loss {val_loss:.4f} | val_acc {val_acc:.4f}\")\n","\n","        # 儲存最好權重 + 早停\n","        if val_acc > best_acc:\n","            best_acc = val_acc\n","            wait = 0\n","            best_path = save_dir / \"best_mobilenetv3_large.pth\"\n","            torch.save(model.state_dict(), best_path)\n","        else:\n","            wait += 1\n","            if wait >= patience:\n","                print(f\"[Early Stop] patience={patience}\")\n","                break\n","\n","    # 存訓練曲線\n","    plt.figure(figsize=(10,4))\n","    plt.subplot(1,2,1); plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"train_loss\"); plt.plot(history[\"epoch\"], history[\"val_loss\"], label=\"val_loss\"); plt.legend(); plt.title(\"Loss\")\n","    plt.subplot(1,2,2); plt.plot(history[\"epoch\"], history[\"val_acc\"], label=\"val_acc\"); plt.legend(); plt.title(\"Val Acc\")\n","    plt.tight_layout()\n","    plt.savefig(save_dir / \"results_curves.png\", dpi=160); plt.close()\n","\n","    with open(save_dir / \"history.json\", \"w\") as f:\n","        json.dump(history, f, indent=2)\n","\n","    return best_path, best_acc\n","\n","# 建立輸出資料夾\n","RUN_DIR = Path(\"/content/runs/cls\") / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","RUN_DIR.mkdir(parents=True, exist_ok=True)\n","\n","best_path, best_acc = train_epochs(model, train_loader, val_loader, CFG[\"epochs\"], RUN_DIR)\n","print(\"Best acc:\", best_acc, \" | best path:\", best_path)\n"],"metadata":{"id":"UXXlid6svW2V","executionInfo":{"status":"aborted","timestamp":1765249454674,"user_tz":-480,"elapsed":6854,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== 8) 使用最佳權重做完整評估（Confusion Matrix / PR 曲線 / report） ====\n","# 重新載入最佳權重\n","model.load_state_dict(torch.load(best_path, map_location=device))\n","val_loss, val_acc, probs, targets = evaluate(model, val_loader)\n","preds = probs.argmax(1)\n","\n","print(f\"[VALID] loss={val_loss:.4f} acc={val_acc:.4f}\")\n","print(\"\\n[Classification Report]\\n\", classification_report(targets, preds, target_names=class_names, digits=4))\n","\n","# Confusion Matrix\n","cm = confusion_matrix(targets, preds, labels=list(range(num_classes)))\n","fig, ax = plt.subplots(figsize=(7,7))\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n","disp.plot(ax=ax, cmap=\"Blues\", colorbar=False, xticks_rotation=45)\n","plt.tight_layout()\n","plt.savefig(RUN_DIR / \"confusion_matrix.png\", dpi=200); plt.close()\n","\n","# PR Curves（每個類別）\n","plt.figure(figsize=(6,5))\n","for i, name in enumerate(class_names):\n","    y_true = (targets == i).astype(int)\n","    precision, recall, _ = precision_recall_curve(y_true, probs[:, i])\n","    ap = average_precision_score(y_true, probs[:, i])\n","    plt.plot(recall, precision, label=f\"{name} AP={ap:.3f}\")\n","plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curves\"); plt.legend()\n","plt.tight_layout()\n","plt.savefig(RUN_DIR / \"pr_curves.png\", dpi=200); plt.close()\n","\n","# 也把報告文字存檔\n","with open(RUN_DIR / \"classification_report.txt\", \"w\") as f:\n","    f.write(classification_report(targets, preds, target_names=class_names, digits=4))\n"],"metadata":{"id":"a4mrFx_sGZkd","executionInfo":{"status":"aborted","timestamp":1765249454676,"user_tz":-480,"elapsed":6854,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== 9) 將整包成果回存到 Google Drive ====\n","SAVE_DIR = Path(SAVE_TO_DRIVE_DIR) / RUN_DIR.name\n","SAVE_DIR.parent.mkdir(parents=True, exist_ok=True)\n","\n","# 拷貝結果\n","if SAVE_DIR.exists():\n","    shutil.rmtree(SAVE_DIR)\n","shutil.copytree(RUN_DIR, SAVE_DIR)\n","\n","print(f\"[OK] 已將結果複製到：{SAVE_DIR}\")\n","\n","# 額外：也把當次使用的 zip 與「偵測到的 train/val 結構」記錄備查\n","shutil.copy(str(zip_local), str(SAVE_DIR / \"source_dataset.zip\"))\n","with open(SAVE_DIR / \"dataset_paths.txt\", \"w\") as f:\n","    f.write(f\"train_dir: {train_dir}\\nval_dir  : {val_dir}\\nclasses  : {class_names}\\n\")\n","print(\"[DONE]\")\n"],"metadata":{"id":"5huqLUSFJG8Q","executionInfo":{"status":"aborted","timestamp":1765249454677,"user_tz":-480,"elapsed":6853,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Re-run only：用已存的最佳權重 + 重新解壓資料集，做完整評估與逐檔 CSV ===\n","!pip -q install torch torchvision timm\n","import os, re, json, zipfile, shutil, glob\n","from pathlib import Path\n","import numpy as np\n","import torch, torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import timm\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_recall_curve, average_precision_score\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# ==== 1) 指定「最佳 run 資料夾」：請把這一行改成你上次結果的資料夾 ====\n","BEST_RUN_DIR = Path(\"/content/drive/MyDrive/Colab_Results/leaf_stage1_cls/20251204\")  # ←改成你的資料夾名稱\n","\n","# 讀最佳權重（預設我上次存成 best_mobilenetv3_large.pth，也容許你換檔名）\n","best_weight = next(iter([*BEST_RUN_DIR.glob(\"best_*.pth\"), *BEST_RUN_DIR.glob(\"*.pth\")]))\n","print(\"[BEST RUN]\", BEST_RUN_DIR)\n","print(\"[BEST WEIGHT]\", best_weight.name)\n","\n","# ==== 2) 重新解壓資料集（用 run 內的 source_dataset.zip） ====\n","zip_path = BEST_RUN_DIR / \"source_dataset.zip\"\n","assert zip_path.exists(), f\"找不到 source_dataset.zip：{zip_path}\"\n","\n","UNZIP_DIR = Path(\"/content/dataset_zip/unzipped\")\n","if UNZIP_DIR.exists():\n","    shutil.rmtree(UNZIP_DIR)\n","UNZIP_DIR.mkdir(parents=True, exist_ok=True)\n","\n","with zipfile.ZipFile(zip_path, \"r\") as zf:\n","    zf.extractall(UNZIP_DIR)\n","\n","# 自動往下找 train/ 與 val/（有時 zip 會多一層資料夾殼）\n","def find_train_val(root: Path):\n","    cand = [root] + [p for p in root.iterdir() if p.is_dir()]\n","    for base in cand:\n","        t, v = base / \"train\", base / \"val\"\n","        if t.exists() and v.exists():\n","            return t, v\n","    raise RuntimeError(\"在解壓路徑中找不到 train/ 與 val/ 目錄\")\n","\n","train_dir, val_dir = find_train_val(UNZIP_DIR)\n","print(\"train_dir :\", train_dir)\n","print(\"val_dir   :\", val_dir)\n","\n","# 類別名以「val 子資料夾」為準（避免名字不同步）\n","class_names = sorted([p.name for p in val_dir.iterdir() if p.is_dir()])\n","num_classes = len(class_names)\n","print(\"classes  :\", class_names)\n","\n","# ==== 3) 建立 DataLoader（只做驗證，不需要 sampler/增強） ====\n","IMG_SIZE = 224\n","BATCH    = 64\n","\n","val_tfms = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n","])\n","val_ds = datasets.ImageFolder(str(val_dir), transform=val_tfms)\n","val_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# ==== 4) 建立同架構模型並載入最佳權重 ====\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = timm.create_model(\"mobilenetv3_large_100\", pretrained=False, num_classes=num_classes)\n","model.load_state_dict(torch.load(best_weight, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# ==== 5) 做完整評估（報表、混淆矩陣、PR 曲線） ====\n","all_probs, all_targets = [], []\n","with torch.no_grad():\n","    for x, y in val_loader:\n","        x = x.to(device)\n","        logits = model(x)\n","        probs = logits.softmax(1).cpu().numpy()\n","        all_probs.append(probs)\n","        all_targets.append(y.numpy())\n","probs   = np.concatenate(all_probs)\n","targets = np.concatenate(all_targets)\n","preds   = probs.argmax(1)\n","\n","# 報表\n","rep_txt = classification_report(targets, preds, target_names=class_names, digits=4)\n","print(rep_txt)\n","(BEST_RUN_DIR / \"reval\").mkdir(exist_ok=True)\n","with open(BEST_RUN_DIR / \"reval\" / \"classification_report_rerun.txt\", \"w\") as f:\n","    f.write(rep_txt)\n","\n","# 混淆矩陣\n","cm = confusion_matrix(targets, preds, labels=list(range(num_classes)))\n","fig, ax = plt.subplots(figsize=(7,7))\n","ConfusionMatrixDisplay(cm, display_labels=class_names).plot(ax=ax, cmap=\"Blues\", colorbar=False, xticks_rotation=45)\n","plt.tight_layout()\n","plt.savefig(BEST_RUN_DIR / \"reval\" / \"confusion_matrix_rerun.png\", dpi=200); plt.close()\n","\n","# PR Curves\n","plt.figure(figsize=(6,5))\n","for i, name in enumerate(class_names):\n","    y_true = (targets == i).astype(int)\n","    from sklearn.metrics import precision_recall_curve, average_precision_score\n","    precision, recall, _ = precision_recall_curve(y_true, probs[:, i])\n","    ap = average_precision_score(y_true, probs[:, i])\n","    plt.plot(recall, precision, label=f\"{name} AP={ap:.3f}\")\n","plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"Precision-Recall Curves (rerun)\"); plt.legend()\n","plt.tight_layout()\n","plt.savefig(BEST_RUN_DIR / \"reval\" / \"pr_curves_rerun.png\", dpi=200); plt.close()\n","\n","# ==== 6) 輸出「逐檔預測」CSV（含你要找的「others → pepper_bell」） ====\n","import csv\n","\n","inv_cls = {i:c for i,c in enumerate(class_names)}\n","rows = []\n","for idx, (path, true_idx) in enumerate(val_ds.imgs):\n","    pred_idx = int(preds[idx])\n","    rows.append({\n","        \"filepath\": path,\n","        \"true_label\": inv_cls[int(true_idx)],\n","        \"pred_label\": inv_cls[pred_idx],\n","        \"correct\"  : int(pred_idx == true_idx),\n","        **{f\"prob_{inv_cls[i]}\": float(probs[idx, i]) for i in range(num_classes)}\n","    })\n","\n","csv_path = BEST_RUN_DIR / \"reval\" / \"val_predictions_rerun.csv\"\n","with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","    writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n","    writer.writeheader(); writer.writerows(rows)\n","print(\"[CSV] 全部驗證檔預測已輸出：\", csv_path)\n","\n","# 只輸出「others → pepper_bell」的誤判清單\n","try:\n","    others_idx      = class_names.index(\"others\")\n","    pepper_bell_idx = class_names.index(\"pepper_bell\")\n","    bad_rows = [r for r in rows if (r[\"true_label\"]==\"others\" and r[\"pred_label\"]==\"pepper_bell\")]\n","    csv_bad = BEST_RUN_DIR / \"reval\" / \"miscls_others_to_pepper_bell.csv\"\n","    with open(csv_bad, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n","        writer.writeheader(); writer.writerows(bad_rows)\n","    print(f\"[CSV] others→pepper_bell 誤判清單共 {len(bad_rows)} 筆：\", csv_bad)\n","except ValueError:\n","    print(\"注意：找不到 'others' 或 'pepper_bell' 類別名稱，請確認資料夾命名。\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnJO8qN5-E6Q","executionInfo":{"status":"ok","timestamp":1765252707436,"user_tz":-480,"elapsed":112203,"user":{"displayName":"Nina Yih","userId":"01177122349699776638"}},"outputId":"07126835-7a1d-4c10-b203-1f124dd40b69"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","[BEST RUN] /content/drive/MyDrive/Colab_Results/leaf_stage1_cls/20251204\n","[BEST WEIGHT] best_mobilenetv3_large.pth\n","train_dir : /content/dataset_zip/unzipped/2025_project_data_CNN_1204/train\n","val_dir   : /content/dataset_zip/unzipped/2025_project_data_CNN_1204/val\n","classes  : ['others', 'pepper_bell', 'potato', 'tomato', 'whole_plant']\n","              precision    recall  f1-score   support\n","\n","      others     1.0000    0.8940    0.9440       500\n"," pepper_bell     0.9357    1.0000    0.9668       495\n","      potato     0.9795    0.9977    0.9885       431\n","      tomato     0.9842    0.9960    0.9901       500\n"," whole_plant     0.9906    1.0000    0.9953       527\n","\n","    accuracy                         0.9772      2453\n","   macro avg     0.9780    0.9775    0.9769      2453\n","weighted avg     0.9782    0.9772    0.9768      2453\n","\n","[CSV] 全部驗證檔預測已輸出： /content/drive/MyDrive/Colab_Results/leaf_stage1_cls/20251204/reval/val_predictions_rerun.csv\n","[CSV] others→pepper_bell 誤判清單共 33 筆： /content/drive/MyDrive/Colab_Results/leaf_stage1_cls/20251204/reval/miscls_others_to_pepper_bell.csv\n"]}]}]}